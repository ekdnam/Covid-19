{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ-HgyUobG-S",
        "colab_type": "code",
        "outputId": "9fcda336-d0e0-4e99-8648-f761296faa3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install  kaggle\n",
        "\n",
        "!mkdir .kaggle\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "mkdir: cannot create directory ‚Äò.kaggle‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAi3U_JNby1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"abolimarathe\",\"key\":\"53f6206052b7e46e5736781e4a76ca15\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLFjCySxb1nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4r_KeO9b5CM",
        "colab_type": "code",
        "outputId": "9801827e-2a23-44bc-d8d2-8637af5b48bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!kaggle config set -n path -v{/content}\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP28miY9b9GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-kud_Ibffc",
        "colab_type": "code",
        "outputId": "a2d2a709-ae3d-411e-aa75-260cb289b2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                           title                                                size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "allen-institute-for-ai/CORD-19-research-challenge             COVID-19 Open Research Dataset Challenge (CORD-19)    3GB  2020-06-05 02:43:46          71785  \n",
            "roche-data-science-coalition/uncover                          UNCOVER COVID-19 Challenge                          179MB  2020-05-21 18:57:53          10483  \n",
            "jessicali9530/animal-crossing-new-horizons-nookplaza-dataset  Animal Crossing New Horizons NookPlaza Catalog      577KB  2020-05-18 22:50:26             42  \n",
            "biancaferreira/african-wildlife                               African Wildlife                                    448MB  2020-05-25 13:42:19              2  \n",
            "siddharthm1698/coursera-course-dataset                        Coursera Course Dataset                              23KB  2020-05-25 05:52:27             10  \n",
            "yamaerenay/spotify-dataset-19212020-160k-tracks               Spotify Dataset 1921-2020, 160k+ Tracks              17MB  2020-05-25 11:31:07             24  \n",
            "stefanlarson/outofscope-intent-classification-dataset         Out-of-Scope Intent Classification Dataset          285KB  2020-05-15 03:04:34              1  \n",
            "ruchi798/movies-on-netflix-prime-video-hulu-and-disney        Movies on Netflix, Prime Video, Hulu and Disney+    627KB  2020-05-22 23:48:01             47  \n",
            "ruchi798/malnutrition-across-the-globe                        Malnutrition across the globe                        79KB  2020-05-25 09:51:45             14  \n",
            "rmjacobsen/property-listings-for-5-south-american-countries   Property Listings for 5 South American Countries    475MB  2020-05-25 02:05:38              1  \n",
            "ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney      TV shows on Netflix, Prime Video, Hulu and Disney+   88KB  2020-05-25 15:38:39             12  \n",
            "kushshah95/the-insurance-company-tic-benchmark                The Insurance Company (TIC) Benchmark               262KB  2020-05-27 16:36:41              1  \n",
            "kianwee/agricultural-raw-material-prices-19902020             Agricultural Raw Material prices (1990-2020)         23KB  2020-05-27 04:51:29              0  \n",
            "gomes555/road-transport-brazil                                Road transport dataset in brazil                     62MB  2020-05-26 02:52:34              4  \n",
            "jessemostipak/marble-racing                                   Marble Racing                                         4KB  2020-06-02 17:08:53              0  \n",
            "devinaconley/covid19-mobility-data                            COVID-19 Google mobility data                         4MB  2020-06-04 12:15:15              2  \n",
            "benroshan/factors-affecting-campus-placement                  Campus Recruitment                                    5KB  2020-04-11 11:09:02           5523  \n",
            "bobbyscience/league-of-legends-diamond-ranked-games-10-min    League of Legends Diamond Ranked Games (10 min)     539KB  2020-04-13 13:53:02           2542  \n",
            "fireballbyedimyrnmom/us-counties-covid-19-dataset             US counties COVID 19 dataset                          2MB  2020-06-05 11:59:45           7247  \n",
            "divyansh22/flight-delay-prediction                            January Flight Delay Prediction                      23MB  2020-04-14 13:15:41           1850  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwB4g-1sbpph",
        "colab_type": "code",
        "outputId": "f673b301-7232-47f2-d803-13d65095bd99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download -d smid80/coronavirus-covid19-tweets-early-april -p /content"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading coronavirus-covid19-tweets-early-april.zip to /content\n",
            " 99% 1.29G/1.30G [00:07<00:00, 164MB/s]\n",
            "100% 1.30G/1.30G [00:07<00:00, 176MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04kqK3oncEzF",
        "colab_type": "code",
        "outputId": "873f5bcb-dfba-4888-c6a4-f093e527a858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  coronavirus-covid19-tweets-early-april.zip\n",
            "  inflating: 2020-03-29 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-03-30 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-03-31 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-01 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-02 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-03 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-04 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-05 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-06 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-07 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-08 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-09 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-10 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-11 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-12 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-13 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-14 Coronavirus Tweets.CSV  \n",
            "  inflating: 2020-04-15 Coronavirus Tweets.CSV  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFQdqAPhcJKk",
        "colab_type": "code",
        "outputId": "5ba76a7e-bf82-4356-8ea9-ce4c1ab47dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from gensim import models, corpora \n",
        "import spacy\n",
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.tokenizer import _get_regex_pattern\n",
        "nlp = spacy.load(\"en_core_web_sm\") \n",
        "import numpy as np \n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_11Eizgq-vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = pd.read_csv(\"2020-03-29 Coronavirus Tweets.CSV\")\n",
        "d2 = pd.read_csv(\"2020-03-30 Coronavirus Tweets.CSV\")\n",
        "d3 = pd.read_csv(\"2020-03-31 Coronavirus Tweets.CSV\")\n",
        "d4 = pd.read_csv(\"2020-04-01 Coronavirus Tweets.CSV\")\n",
        "d5 = pd.read_csv(\"2020-04-02 Coronavirus Tweets.CSV\")\n",
        "d6 = pd.read_csv(\"2020-04-03 Coronavirus Tweets.CSV\")\n",
        "d7 = pd.read_csv(\"2020-04-04 Coronavirus Tweets.CSV\")\n",
        "d8 = pd.read_csv(\"2020-04-05 Coronavirus Tweets.CSV\")\n",
        "d9 = pd.read_csv(\"2020-04-06 Coronavirus Tweets.CSV\")\n",
        "d10 = pd.read_csv(\"2020-04-07 Coronavirus Tweets.CSV\")\n",
        "d11 = pd.read_csv(\"2020-04-08 Coronavirus Tweets.CSV\")\n",
        "d12 = pd.read_csv(\"2020-04-09 Coronavirus Tweets.CSV\")\n",
        "d13 = pd.read_csv(\"2020-04-10 Coronavirus Tweets.CSV\")\n",
        "d14 = pd.read_csv(\"2020-04-11 Coronavirus Tweets.CSV\")\n",
        "d15 = pd.read_csv(\"2020-04-12 Coronavirus Tweets.CSV\")\n",
        "d16 = pd.read_csv(\"2020-04-13 Coronavirus Tweets.CSV\")\n",
        "d17 = pd.read_csv(\"2020-04-14 Coronavirus Tweets.CSV\")\n",
        "d18 = pd.read_csv(\"2020-04-15 Coronavirus Tweets.CSV\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av-HkiLjcJHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1= d1[['text','lang','country_code','created_at']]\n",
        "d1 = d1[d1['lang']=='en']\n",
        "\n",
        "d2= d2[['text','lang','country_code','created_at']]\n",
        "d2 = d2[d2['lang']=='en']\n",
        "\n",
        "d3= d3[['text','lang','country_code','created_at']]\n",
        "d3 = d3[d3['lang']=='en']\n",
        "\n",
        "d4= d4[['text','lang','country_code','created_at']]\n",
        "d4 = d4[d4['lang']=='en']\n",
        "\n",
        "d5= d5[['text','lang','country_code','created_at']]\n",
        "d5 = d5[d5['lang']=='en']\n",
        "\n",
        "d6= d6[['text','lang','country_code','created_at']]\n",
        "d6 = d6[d6['lang']=='en']\n",
        "\n",
        "d7= d7[['text','lang','country_code','created_at']]\n",
        "d7 = d7[d7['lang']=='en']\n",
        "\n",
        "d8= d8[['text','lang','country_code','created_at']]\n",
        "d8 = d8[d8['lang']=='en']\n",
        "\n",
        "d9= d9[['text','lang','country_code','created_at']]\n",
        "d9 = d9[d9['lang']=='en']\n",
        "\n",
        "d10= d10[['text','lang','country_code','created_at']]\n",
        "d10 = d10[d10['lang']=='en']\n",
        "\n",
        "d11= d11[['text','lang','country_code','created_at']]\n",
        "d11 = d11[d11['lang']=='en']\n",
        "\n",
        "d12= d12[['text','lang','country_code','created_at']]\n",
        "d12 = d12[d12['lang']=='en']\n",
        "\n",
        "d13= d13[['text','lang','country_code','created_at']]\n",
        "d13 = d13[d13['lang']=='en']\n",
        "\n",
        "d14= d14[['text','lang','country_code','created_at']]\n",
        "d14 = d14[d14['lang']=='en']\n",
        "\n",
        "d15= d15[['text','lang','country_code','created_at']]\n",
        "d15 = d15[d15['lang']=='en']\n",
        "\n",
        "d16= d16[['text','lang','country_code','created_at']]\n",
        "d16 = d16[d16['lang']=='en']\n",
        "\n",
        "d17= d17[['text','lang','country_code','created_at']]\n",
        "d17 = d17[d17['lang']=='en']\n",
        "\n",
        "d18= d18[['text','lang','country_code','created_at']]\n",
        "d18 = d18[d18['lang']=='en']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "locjKPPVcJDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1.dropna(inplace=True)\n",
        "d2.dropna(inplace=True)\n",
        "d3.dropna(inplace=True)\n",
        "d4.dropna(inplace=True)\n",
        "d5.dropna(inplace=True)\n",
        "d6.dropna(inplace=True)\n",
        "d7.dropna(inplace=True)\n",
        "d8.dropna(inplace=True)\n",
        "d9.dropna(inplace=True)\n",
        "d10.dropna(inplace=True)\n",
        "d11.dropna(inplace=True)\n",
        "d12.dropna(inplace=True)\n",
        "d13.dropna(inplace=True)\n",
        "d14.dropna(inplace=True)\n",
        "d15.dropna(inplace=True)\n",
        "d16.dropna(inplace=True)\n",
        "d17.dropna(inplace=True)\n",
        "d18.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpX7LRJJcJAo",
        "colab_type": "code",
        "outputId": "50177f37-e9be-4dee-bb7b-9423ab05a987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "d3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>This is how far back they have to put the swab...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T00:00:04Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Mayor @KeishaBottoms to WH on #COVID19 - ‚ÄúAllo...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T00:00:05Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>Big trip 5 mi to north...checked out Yountvill...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T00:00:18Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>Nurses are being threatened and disciplined fo...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T00:00:21Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>What colour is that virus? #coronavirus https:...</td>\n",
              "      <td>en</td>\n",
              "      <td>AU</td>\n",
              "      <td>2020-03-31T00:00:25Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669727</th>\n",
              "      <td>YOU OK WITH THIS DOCTOR SENATOR @BillCassidy ?...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T23:59:40Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669736</th>\n",
              "      <td>This a good look? üò∑\\n‚ñ™Ô∏è‚ñ™Ô∏è‚ñ™Ô∏è\\n‚ñ™Ô∏è‚ñ™Ô∏è‚ñ™Ô∏è\\n#coronavi...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T23:59:42Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669753</th>\n",
              "      <td>Every question from each journalist at tomorro...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-31T23:59:46Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669789</th>\n",
              "      <td>This may be the first time I actually want som...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-31T23:59:53Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669795</th>\n",
              "      <td>It‚Äôs my Birthday üéÇ #stuck #inside #coronavirus...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-31T23:59:54Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18381 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...            created_at\n",
              "203     This is how far back they have to put the swab...  ...  2020-03-31T00:00:04Z\n",
              "220     Mayor @KeishaBottoms to WH on #COVID19 - ‚ÄúAllo...  ...  2020-03-31T00:00:05Z\n",
              "394     Big trip 5 mi to north...checked out Yountvill...  ...  2020-03-31T00:00:18Z\n",
              "435     Nurses are being threatened and disciplined fo...  ...  2020-03-31T00:00:21Z\n",
              "485     What colour is that virus? #coronavirus https:...  ...  2020-03-31T00:00:25Z\n",
              "...                                                   ...  ...                   ...\n",
              "669727  YOU OK WITH THIS DOCTOR SENATOR @BillCassidy ?...  ...  2020-03-31T23:59:40Z\n",
              "669736  This a good look? üò∑\\n‚ñ™Ô∏è‚ñ™Ô∏è‚ñ™Ô∏è\\n‚ñ™Ô∏è‚ñ™Ô∏è‚ñ™Ô∏è\\n#coronavi...  ...  2020-03-31T23:59:42Z\n",
              "669753  Every question from each journalist at tomorro...  ...  2020-03-31T23:59:46Z\n",
              "669789  This may be the first time I actually want som...  ...  2020-03-31T23:59:53Z\n",
              "669795  It‚Äôs my Birthday üéÇ #stuck #inside #coronavirus...  ...  2020-03-31T23:59:54Z\n",
              "\n",
              "[18381 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyZ7EZ-vcI9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1.reset_index(inplace = True) \n",
        "d2.reset_index(inplace = True)\n",
        "d3.reset_index(inplace = True)\n",
        "d4.reset_index(inplace = True)\n",
        "d5.reset_index(inplace = True)\n",
        "d6.reset_index(inplace = True)\n",
        "d7.reset_index(inplace = True)\n",
        "d8.reset_index(inplace = True)\n",
        "d9.reset_index(inplace = True)\n",
        "d10.reset_index(inplace = True)\n",
        "d11.reset_index(inplace = True)\n",
        "d12.reset_index(inplace = True)\n",
        "d13.reset_index(inplace = True)\n",
        "d14.reset_index(inplace = True)\n",
        "d15.reset_index(inplace = True)\n",
        "d16.reset_index(inplace = True)\n",
        "d17.reset_index(inplace = True)\n",
        "d18.reset_index(inplace = True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new = d1[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d1[\"date\"]= new[0] \n",
        "d1[\"time\"]= new[1] \n",
        "\n",
        "new = d2[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d2[\"date\"]= new[0] \n",
        "d2[\"time\"]= new[1] \n",
        "\n",
        "new = d3[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d3[\"date\"]= new[0] \n",
        "d3[\"time\"]= new[1] \n",
        "\n",
        "new = d4[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d4[\"date\"]= new[0] \n",
        "d4[\"time\"]= new[1] \n",
        "\n",
        "new = d5[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d5[\"date\"]= new[0] \n",
        "d5[\"time\"]= new[1] \n",
        "\n",
        "new = d6[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d6[\"date\"]= new[0] \n",
        "d6[\"time\"]= new[1] \n",
        "\n",
        "new = d7[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d7[\"date\"]= new[0] \n",
        "d7[\"time\"]= new[1] \n",
        "\n",
        "new = d8[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d8[\"date\"]= new[0] \n",
        "d8[\"time\"]= new[1] \n",
        "\n",
        "new = d9[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d9[\"date\"]= new[0] \n",
        "d9[\"time\"]= new[1] \n",
        "\n",
        "new = d10[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d10[\"date\"]= new[0] \n",
        "d10[\"time\"]= new[1] \n",
        "\n",
        "new = d11[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d11[\"date\"]= new[0] \n",
        "d11[\"time\"]= new[1] \n",
        "\n",
        "new = d12[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d12[\"date\"]= new[0] \n",
        "d12[\"time\"]= new[1] \n",
        "\n",
        "new = d13[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d13[\"date\"]= new[0] \n",
        "d13[\"time\"]= new[1] \n",
        "\n",
        "new = d14[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d14[\"date\"]= new[0] \n",
        "d14[\"time\"]= new[1] \n",
        "\n",
        "new = d15[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d15[\"date\"]= new[0] \n",
        "d15[\"time\"]= new[1] \n",
        "\n",
        "new = d16[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d16[\"date\"]= new[0] \n",
        "d16[\"time\"]= new[1] \n",
        "\n",
        "new = d17[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d17[\"date\"]= new[0] \n",
        "d17[\"time\"]= new[1] \n",
        "\n",
        "new = d18[\"created_at\"].str.split(\"T\", n = 1, expand = True)\n",
        "d18[\"date\"]= new[0] \n",
        "d18[\"time\"]= new[1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bkk-KtkcI52",
        "colab_type": "code",
        "outputId": "950c8bc8-51f3-4d55-e4af-45c7ca18955f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(d1) +len(d2)+len(d3)+len(d4)+len(d5)+len(d6)+len(d7)+len(d8)+len(d9)+len(d10)+len(d11)+len(d12)+len(d13)+len(d14)+len(d15)+len(d16)+len(d17)+len(d18)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCuvuwHAcI2e",
        "colab_type": "code",
        "outputId": "2824d8ba-74fa-4127-9961-19c35c674ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UzH-FD3tmTX",
        "colab_type": "code",
        "outputId": "c15826db-a6cf-4273-f022-8d1d51dcfbf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "d1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>293</td>\n",
              "      <td>@ClayTravis FLU? This seems fishy to me these ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:16Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:16Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>393</td>\n",
              "      <td>@netflix omg!!! Ozark ending was to die for!!!...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:29Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:29Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>481</td>\n",
              "      <td>I don't think there is gd leadership across th...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:39Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:39Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>499</td>\n",
              "      <td>In a change of conversation from #covid19 here...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>Any other hospital doing this? Our engineering...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17850</th>\n",
              "      <td>564053</td>\n",
              "      <td>I am surprised too &amp;gt; ‚ÄúLocal leaders and som...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T23:59:41Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>23:59:41Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17851</th>\n",
              "      <td>564102</td>\n",
              "      <td>In my chair, tv on awaiting the 1pm briefing w...</td>\n",
              "      <td>en</td>\n",
              "      <td>NZ</td>\n",
              "      <td>2020-03-29T23:59:52Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>23:59:52Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17852</th>\n",
              "      <td>564113</td>\n",
              "      <td>Another 30! #socialdistancing #coronavirus #co...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T23:59:54Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>23:59:54Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17853</th>\n",
              "      <td>564114</td>\n",
              "      <td>#Covid_19 relief. Better things to talk about ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T23:59:54Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>23:59:54Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17854</th>\n",
              "      <td>564119</td>\n",
              "      <td>@nichmelbourne @GemmaTognini @ScottMorrisonMP ...</td>\n",
              "      <td>en</td>\n",
              "      <td>AU</td>\n",
              "      <td>2020-03-29T23:59:55Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>23:59:55Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17855 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        index  ...       time\n",
              "0         293  ...  00:00:16Z\n",
              "1         393  ...  00:00:29Z\n",
              "2         481  ...  00:00:39Z\n",
              "3         499  ...  00:00:42Z\n",
              "4         500  ...  00:00:42Z\n",
              "...       ...  ...        ...\n",
              "17850  564053  ...  23:59:41Z\n",
              "17851  564102  ...  23:59:52Z\n",
              "17852  564113  ...  23:59:54Z\n",
              "17853  564114  ...  23:59:54Z\n",
              "17854  564119  ...  23:59:55Z\n",
              "\n",
              "[17855 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9zFfBGmNY9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZih0WszXWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1 = d1.append(d2)\n",
        "d1 =d1.append(d3)\n",
        "d1 =d1.append(d4)\n",
        "d1 =d1.append(d5)\n",
        "d1 =d1.append(d6)\n",
        "d1 =d1.append(d7)\n",
        "d1 =d1.append(d8)\n",
        "d1 =d1.append(d9)\n",
        "d1 =d1.append(d10)\n",
        "d1 =d1.append(d11)\n",
        "d1 =d1.append(d12)\n",
        "d1 =d1.append(d13)\n",
        "d1 =d1.append(d14)\n",
        "d1 =d1.append(d15)\n",
        "d1 =d1.append(d16)\n",
        "d1 =d1.append(d17)\n",
        "d1 =d1.append(d18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuQ1uNV4NbCa",
        "colab_type": "code",
        "outputId": "bc411d3e-273f-40f9-a302-5830547a9720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "hashtags = d1['text'].apply(lambda x: re.findall(r'\\B#\\w*[a-zA-Z]+\\w*',x))\n",
        "print(hashtags)\n",
        "print(len(hashtags))\n",
        "d1['hashtag'] = hashtags"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                              [#Covid_19]\n",
            "1                                               [#COVID19]\n",
            "2                                               [#COVID19]\n",
            "3        [#covid19, #cavalierkingcharles, #daftdug, #La...\n",
            "4                                 [#Covid_19, #medtwitter]\n",
            "                               ...                        \n",
            "11415        [#WHO, #COVID19, #coronavirus, #GlobalHealth]\n",
            "11416             [#COVID19, #everyproblemisanopportunity]\n",
            "11417                             [#coronavirus, #Science]\n",
            "11418                                           [#COVID19]\n",
            "11419                               [#CoronavirusPandemic]\n",
            "Name: text, Length: 230769, dtype: object\n",
            "230769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ld1mw5zzO9",
        "colab_type": "code",
        "outputId": "6f45ab85-6cc7-4a10-e1c9-7fb549fb79cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(d1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kenieRUBzzLs",
        "colab_type": "code",
        "outputId": "d6128575-739b-4e36-9ade-04459ecf7914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "d1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>hashtag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>293</td>\n",
              "      <td>@ClayTravis FLU? This seems fishy to me these ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:16Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:16Z</td>\n",
              "      <td>[#Covid_19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>393</td>\n",
              "      <td>@netflix omg!!! Ozark ending was to die for!!!...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:29Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:29Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>481</td>\n",
              "      <td>I don't think there is gd leadership across th...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:39Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:39Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>499</td>\n",
              "      <td>In a change of conversation from #covid19 here...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#covid19, #cavalierkingcharles, #daftdug, #La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>Any other hospital doing this? Our engineering...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#Covid_19, #medtwitter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11415</th>\n",
              "      <td>475039</td>\n",
              "      <td>‚ÄúThe #WHO is bureaucratic, frustrating, timid ...</td>\n",
              "      <td>en</td>\n",
              "      <td>CA</td>\n",
              "      <td>2020-04-15T23:59:07Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:07Z</td>\n",
              "      <td>[#WHO, #COVID19, #coronavirus, #GlobalHealth]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11416</th>\n",
              "      <td>475072</td>\n",
              "      <td>@CEO_CleMetParks sir! Some positive offshoots ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#COVID19, #everyproblemisanopportunity]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11417</th>\n",
              "      <td>475075</td>\n",
              "      <td>The good news is that the Iranian Revolutionar...</td>\n",
              "      <td>en</td>\n",
              "      <td>IR</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#coronavirus, #Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11418</th>\n",
              "      <td>475191</td>\n",
              "      <td>Remember when the Soviet Union told the world ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:46Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:46Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11419</th>\n",
              "      <td>475199</td>\n",
              "      <td>@UMNExtFD @UMNExt @FOX9 And here's the story w...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:47Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:47Z</td>\n",
              "      <td>[#CoronavirusPandemic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230769 rows √ó 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        index  ...                                            hashtag\n",
              "0         293  ...                                        [#Covid_19]\n",
              "1         393  ...                                         [#COVID19]\n",
              "2         481  ...                                         [#COVID19]\n",
              "3         499  ...  [#covid19, #cavalierkingcharles, #daftdug, #La...\n",
              "4         500  ...                           [#Covid_19, #medtwitter]\n",
              "...       ...  ...                                                ...\n",
              "11415  475039  ...      [#WHO, #COVID19, #coronavirus, #GlobalHealth]\n",
              "11416  475072  ...           [#COVID19, #everyproblemisanopportunity]\n",
              "11417  475075  ...                           [#coronavirus, #Science]\n",
              "11418  475191  ...                                         [#COVID19]\n",
              "11419  475199  ...                             [#CoronavirusPandemic]\n",
              "\n",
              "[230769 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfZnfDvC2YaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1.reset_index(inplace=True)\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "\n",
        "emoticons_happy = set([\n",
        "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
        "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
        "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
        "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
        "    '<3'\n",
        "    ])\n",
        "\n",
        "# Sad Emoticons\n",
        "emoticons_sad = set([\n",
        "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
        "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
        "    ':c', ':{', '>:\\\\', ';('\n",
        "    ])\n",
        "\n",
        "#Emoji patterns\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "         u\"\\U00002702-\\U000027B0\"\n",
        "         u\"\\U000024C2-\\U0001F251\"\n",
        "         \"]+\", flags=re.UNICODE)\n",
        "\n",
        "\n",
        "#combine sad and happy emoticons\n",
        "emoticons = emoticons_happy.union(emoticons_sad)\n",
        "\n",
        "def clean_tweets(tweet):\n",
        " \n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(tweet)\n",
        "    #removing mentions\n",
        "    tweet = re.sub(r':', '', tweet)\n",
        "    tweet = re.sub(r'‚Äö√Ñ¬∂', '', tweet)\n",
        "#replace consecutive non-ASCII characters with a space\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
        "#remove emojis from tweet\n",
        "    tweet = emoji_pattern.sub(r'', tweet)\n",
        "#filter using NLTK library append it to a string\n",
        "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
        "    filtered_tweet = []\n",
        "#looping through conditions\n",
        "    for w in word_tokens:\n",
        "#check tokens against stop words , emoticons and punctuations\n",
        "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
        "            filtered_tweet.append(w)\n",
        "    return ' '.join(filtered_tweet)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDQ3WZHFKioz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re #regular expressions\n",
        "import string \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "reuse = False\n",
        "i =0 \n",
        "\n",
        "for tweet in d1[\"text\"]:\n",
        "  \n",
        "   d1.at[i,\"text\"] = clean_tweets(tweet)\n",
        "   i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhuFdj762YUR",
        "colab_type": "code",
        "outputId": "166ffa57-ce05-4dd6-860c-04524469ded4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "d1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>hashtag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>293</td>\n",
              "      <td>ClayTravis FLU This seems fishy Covid_19 numbe...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:16Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:16Z</td>\n",
              "      <td>[#Covid_19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>393</td>\n",
              "      <td>netflix omg Ozark ending die Thanks distractio...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:29Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:29Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>481</td>\n",
              "      <td>I n't think gd leadership across states I see ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:39Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:39Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>499</td>\n",
              "      <td>In change conversation covid19 Charlie watchin...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#covid19, #cavalierkingcharles, #daftdug, #La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>500</td>\n",
              "      <td>Any hospital Our engineering department helped...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#Covid_19, #medtwitter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230764</th>\n",
              "      <td>11415</td>\n",
              "      <td>475039</td>\n",
              "      <td>‚Äú The WHO bureaucratic frustrating timid ‚Äî ind...</td>\n",
              "      <td>en</td>\n",
              "      <td>CA</td>\n",
              "      <td>2020-04-15T23:59:07Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:07Z</td>\n",
              "      <td>[#WHO, #COVID19, #coronavirus, #GlobalHealth]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230765</th>\n",
              "      <td>11416</td>\n",
              "      <td>475072</td>\n",
              "      <td>CEO_CleMetParks sir Some positive offshoots CO...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#COVID19, #everyproblemisanopportunity]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230766</th>\n",
              "      <td>11417</td>\n",
              "      <td>475075</td>\n",
              "      <td>The good news Iranian Revolutionary Guards bui...</td>\n",
              "      <td>en</td>\n",
              "      <td>IR</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#coronavirus, #Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230767</th>\n",
              "      <td>11418</td>\n",
              "      <td>475191</td>\n",
              "      <td>Remember Soviet Union told world advanced nucl...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:46Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:46Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230768</th>\n",
              "      <td>11419</td>\n",
              "      <td>475199</td>\n",
              "      <td>UMNExtFD UMNExt FOX9 And 's story video link T...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:47Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:47Z</td>\n",
              "      <td>[#CoronavirusPandemic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230769 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        level_0  ...                                            hashtag\n",
              "0             0  ...                                        [#Covid_19]\n",
              "1             1  ...                                         [#COVID19]\n",
              "2             2  ...                                         [#COVID19]\n",
              "3             3  ...  [#covid19, #cavalierkingcharles, #daftdug, #La...\n",
              "4             4  ...                           [#Covid_19, #medtwitter]\n",
              "...         ...  ...                                                ...\n",
              "230764    11415  ...      [#WHO, #COVID19, #coronavirus, #GlobalHealth]\n",
              "230765    11416  ...           [#COVID19, #everyproblemisanopportunity]\n",
              "230766    11417  ...                           [#coronavirus, #Science]\n",
              "230767    11418  ...                                         [#COVID19]\n",
              "230768    11419  ...                             [#CoronavirusPandemic]\n",
              "\n",
              "[230769 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHWyEg9t2YRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1['text']= d1['text'].replace({'\\n':\" \",\"\\t\":\" \"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH_vKw0Jwmvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk \n",
        "import re \n",
        "import numpy as np \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M32Kho3GwmsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i =0 \n",
        "\n",
        "for tweet in d1[\"text\"]:\n",
        "  \n",
        "   d1.at[i,\"text\"] = str(tweet).lower()\n",
        "   \n",
        "   i = i + 1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNK5syp4O_yJ",
        "colab_type": "code",
        "outputId": "638f3850-0511-4dae-eb2e-2ca7d7a92552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "d1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>hashtag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>293</td>\n",
              "      <td>claytravis flu this seems fishy covid_19 numbe...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:16Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:16Z</td>\n",
              "      <td>[#Covid_19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>393</td>\n",
              "      <td>netflix omg ozark ending die thanks distractio...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:29Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:29Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>481</td>\n",
              "      <td>i n't think gd leadership across states i see ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:39Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:39Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>499</td>\n",
              "      <td>in change conversation covid19 charlie watchin...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#covid19, #cavalierkingcharles, #daftdug, #La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>500</td>\n",
              "      <td>any hospital our engineering department helped...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#Covid_19, #medtwitter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230764</th>\n",
              "      <td>11415</td>\n",
              "      <td>475039</td>\n",
              "      <td>‚Äú the who bureaucratic frustrating timid ‚Äî ind...</td>\n",
              "      <td>en</td>\n",
              "      <td>CA</td>\n",
              "      <td>2020-04-15T23:59:07Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:07Z</td>\n",
              "      <td>[#WHO, #COVID19, #coronavirus, #GlobalHealth]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230765</th>\n",
              "      <td>11416</td>\n",
              "      <td>475072</td>\n",
              "      <td>ceo_clemetparks sir some positive offshoots co...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#COVID19, #everyproblemisanopportunity]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230766</th>\n",
              "      <td>11417</td>\n",
              "      <td>475075</td>\n",
              "      <td>the good news iranian revolutionary guards bui...</td>\n",
              "      <td>en</td>\n",
              "      <td>IR</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#coronavirus, #Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230767</th>\n",
              "      <td>11418</td>\n",
              "      <td>475191</td>\n",
              "      <td>remember soviet union told world advanced nucl...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:46Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:46Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230768</th>\n",
              "      <td>11419</td>\n",
              "      <td>475199</td>\n",
              "      <td>umnextfd umnext fox9 and 's story video link t...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:47Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:47Z</td>\n",
              "      <td>[#CoronavirusPandemic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230769 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        level_0  ...                                            hashtag\n",
              "0             0  ...                                        [#Covid_19]\n",
              "1             1  ...                                         [#COVID19]\n",
              "2             2  ...                                         [#COVID19]\n",
              "3             3  ...  [#covid19, #cavalierkingcharles, #daftdug, #La...\n",
              "4             4  ...                           [#Covid_19, #medtwitter]\n",
              "...         ...  ...                                                ...\n",
              "230764    11415  ...      [#WHO, #COVID19, #coronavirus, #GlobalHealth]\n",
              "230765    11416  ...           [#COVID19, #everyproblemisanopportunity]\n",
              "230766    11417  ...                           [#coronavirus, #Science]\n",
              "230767    11418  ...                                         [#COVID19]\n",
              "230768    11419  ...                             [#CoronavirusPandemic]\n",
              "\n",
              "[230769 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trNFedhFPFE7",
        "colab_type": "code",
        "outputId": "0839288d-ec89-4c64-c9f0-00c58b62cb1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "d1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>hashtag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>293</td>\n",
              "      <td>claytravis flu this seems fishy covid_19 numbe...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:16Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:16Z</td>\n",
              "      <td>[#Covid_19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>393</td>\n",
              "      <td>netflix omg ozark ending die thanks distractio...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:29Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:29Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>481</td>\n",
              "      <td>i n't think gd leadership across states i see ...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:39Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:39Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>499</td>\n",
              "      <td>in change conversation covid19 charlie watchin...</td>\n",
              "      <td>en</td>\n",
              "      <td>GB</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#covid19, #cavalierkingcharles, #daftdug, #La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>500</td>\n",
              "      <td>any hospital our engineering department helped...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-03-29T00:00:42Z</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>00:00:42Z</td>\n",
              "      <td>[#Covid_19, #medtwitter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230764</th>\n",
              "      <td>11415</td>\n",
              "      <td>475039</td>\n",
              "      <td>‚Äú the who bureaucratic frustrating timid ‚Äî ind...</td>\n",
              "      <td>en</td>\n",
              "      <td>CA</td>\n",
              "      <td>2020-04-15T23:59:07Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:07Z</td>\n",
              "      <td>[#WHO, #COVID19, #coronavirus, #GlobalHealth]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230765</th>\n",
              "      <td>11416</td>\n",
              "      <td>475072</td>\n",
              "      <td>ceo_clemetparks sir some positive offshoots co...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#COVID19, #everyproblemisanopportunity]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230766</th>\n",
              "      <td>11417</td>\n",
              "      <td>475075</td>\n",
              "      <td>the good news iranian revolutionary guards bui...</td>\n",
              "      <td>en</td>\n",
              "      <td>IR</td>\n",
              "      <td>2020-04-15T23:59:15Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:15Z</td>\n",
              "      <td>[#coronavirus, #Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230767</th>\n",
              "      <td>11418</td>\n",
              "      <td>475191</td>\n",
              "      <td>remember soviet union told world advanced nucl...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:46Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:46Z</td>\n",
              "      <td>[#COVID19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230768</th>\n",
              "      <td>11419</td>\n",
              "      <td>475199</td>\n",
              "      <td>umnextfd umnext fox9 and 's story video link t...</td>\n",
              "      <td>en</td>\n",
              "      <td>US</td>\n",
              "      <td>2020-04-15T23:59:47Z</td>\n",
              "      <td>2020-04-15</td>\n",
              "      <td>23:59:47Z</td>\n",
              "      <td>[#CoronavirusPandemic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230769 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        level_0  ...                                            hashtag\n",
              "0             0  ...                                        [#Covid_19]\n",
              "1             1  ...                                         [#COVID19]\n",
              "2             2  ...                                         [#COVID19]\n",
              "3             3  ...  [#covid19, #cavalierkingcharles, #daftdug, #La...\n",
              "4             4  ...                           [#Covid_19, #medtwitter]\n",
              "...         ...  ...                                                ...\n",
              "230764    11415  ...      [#WHO, #COVID19, #coronavirus, #GlobalHealth]\n",
              "230765    11416  ...           [#COVID19, #everyproblemisanopportunity]\n",
              "230766    11417  ...                           [#coronavirus, #Science]\n",
              "230767    11418  ...                                         [#COVID19]\n",
              "230768    11419  ...                             [#CoronavirusPandemic]\n",
              "\n",
              "[230769 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuAbO7AIgWty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "09b625e4-18ac-4829-e185-4df8de6945b9"
      },
      "source": [
        "import os, sys, glob\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('rslp')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "!pip install mglearn\n",
        "import mglearn\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "Collecting mglearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/8aced26fce0b2ae82c3c87cd3b6105f38ca6d9d51704ecc44aa54473e6b9/mglearn-0.1.9.tar.gz (540kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 542kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mglearn) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mglearn) (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from mglearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mglearn) (1.0.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from mglearn) (7.0.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from mglearn) (0.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from mglearn) (2.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from mglearn) (0.15.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mglearn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mglearn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mglearn) (2.4.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->mglearn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mglearn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler->mglearn) (1.12.0)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=08f183c8a59a89554ddf00cd5f38ccd894a620669e573eff7dd146fcbbcd4b5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/a6/ea/a6a3716233fa62fc561259b5cb1e28f79e9ff3592c0adac5f0\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrPFYFm_rdc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NMF_model(keyword,data,max_df,min_df,n_components, n_grams):\n",
        "    tfidf = TfidfVectorizer(ngram_range=n_grams, max_df=max_df,min_df = min_df) \n",
        "    X = tfidf.fit_transform(data)\n",
        "\n",
        "    # Fit the model\n",
        "    nmf = NMF(n_components=n_components,random_state=0)\n",
        "    topics = nmf.fit_transform(X)\n",
        "\n",
        "    # Normalize\n",
        "    normalizer = Normalizer()\n",
        "    topics_norm = normalizer.fit_transform(topics)\n",
        "    \n",
        "    # Assigning component number to each document\n",
        "    topic_number = np.argmax(topics_norm,axis=1)\n",
        "    \n",
        "    # Counting number of documents in each component\n",
        "    counts = pd.Series(topic_number).value_counts()\n",
        "    \n",
        "    # Plotting number of documents in each component\n",
        "    plt.bar(pd.Series(topic_number).unique(),counts)\n",
        "    \n",
        "    # Top 10 words for each component\n",
        "    d = nmf.components_\n",
        "    w = tfidf.get_feature_names()\n",
        "    words = []\n",
        "    for r in range(len(d)):\n",
        "        a = sorted([(v,i) for i,v in enumerate(d[r])],reverse=True)[0:20]\n",
        "        words.append([w[e[1]] for e in a])\n",
        "    \n",
        "    # Printing words per topic\n",
        "    print('\\n Topics\\n')\n",
        "    print(keyword)\n",
        "    feature_names = np.array(tfidf.get_feature_names())\n",
        "    sorting = np.argsort(nmf.components_, axis=1)[:, ::-1]\n",
        "    mglearn.tools.print_topics(topics=range(n_components), feature_names = feature_names, sorting=sorting, topics_per_chunk=5,n_words=20)\n",
        "\n",
        "    return topics_norm, topic_number, words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFE2xi1uriV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ba6a4f6-588d-4d17-b12c-d6bec4adf920"
      },
      "source": [
        "d1.text = d1.text.astype(str)\n",
        "topics_norm, topic_number, words = NMF_model(10,d1.text, 0.5 , 1 , 30, (1,1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Topics\n",
            "\n",
            "10\n",
            "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
            "--------      --------      --------      --------      --------      \n",
            "people        cases         stay          coronavirus   covid_19      \n",
            "many          deaths        home          covid„Éº19      stayathomeandstaysafe\n",
            "died          confirmed     safe          death         borisjohnson  \n",
            "dying         total         healthy       000           coronaupdate  \n",
            "still         000           everyone      toll          corona        \n",
            "die           number        at            latest        lockdowneffect\n",
            "tested        reported      save          news          boris         \n",
            "virus         positive      staying       authorities   covid2019     \n",
            "need          death         order         tweets        coronavirustruth\n",
            "positive      recovered     lives         covid2019     coronalockdown\n",
            "think         nigeria       be            covid19pandemicvirus         \n",
            "know          april         stayhomesavelivesmasks         socialdistancing\n",
            "infected      today         wash          canadian      hope          \n",
            "government    million       strong        how           news          \n",
            "why           10            hands         spain         whencoronavirusisover\n",
            "there         state         working       what          stayathome    \n",
            "lives         discharged    stayathome    outbreak      recovery      \n",
            "stop          worldwide     inside        hclrghbcgf    what          \n",
            "understand    update        work          china         thelockdown   \n",
            "how           county        protect       surpasses     2020          \n",
            "\n",
            "\n",
            "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
            "--------      --------      --------      --------      --------      \n",
            "million       nhs           amp           covid         we            \n",
            "cancelstudentdebtkeep          support       19            need          \n",
            "studentdebtstimuluspetition      family        positive      together      \n",
            "stimulate     via           today         corona        re            \n",
            "debt          sign          community     coronavirusoutbreaksupport       \n",
            "student       ukchange      food          update        fight         \n",
            "package       uk            due           patients      must          \n",
            "urge          ppe           live          via           friends       \n",
            "45            frontline     our           test          help          \n",
            "economy       all           great         covid„Éº19      stand         \n",
            "next          govt          staff         virus         times         \n",
            "help          provide       others        coronavirusupdatescommunity     \n",
            "needed        safe          team          tested        beat          \n",
            "senatemajldr  staff         my            first         continue      \n",
            "speakerpelosi youtube       many          disease       hope          \n",
            "coronavirus   test          medical       died          win           \n",
            "people        moneyforthepeoplein            youtube       shall         \n",
            "senschumer    change        patients      fight         working       \n",
            "gopleader     2000          must          updates       overcome      \n",
            "worldwide     boris         response      alerted       crisis        \n",
            "\n",
            "\n",
            "topic 10      topic 11      topic 12      topic 13      topic 14      \n",
            "--------      --------      --------      --------      --------      \n",
            "trump         the           new           help          us            \n",
            "realdonaldtrumpto            york          well          let           \n",
            "who           of            city          spread        000           \n",
            "president     in            nyc           even          god           \n",
            "says          government    normal        feel          death         \n",
            "he            is            state         symptoms      toll          \n",
            "americans     and           newyork       app           help          \n",
            "potus         virus         jersey        self          join          \n",
            "america       way           deaths        daily         may           \n",
            "said          for           reports       slow          give          \n",
            "donald        best          total         risk          protect       \n",
            "states        thing         brooklyn      download      keep          \n",
            "would         state         newyorkcity   sooner        allah         \n",
            "cnn           are           yorkers       identify      tell          \n",
            "media         2020          zealand       reporting     100           \n",
            "funding       number        record        cases         deaths        \n",
            "gop           crisis        orleans       stop          save          \n",
            "press         country       manhattan     done          surpasses     \n",
            "hoax          states        cuomo         isolation     pray          \n",
            "trumppressconfreal          today         prevent       lord          \n",
            "\n",
            "\n",
            "topic 15      topic 16      topic 17      topic 18      topic 19      \n",
            "--------      --------      --------      --------      --------      \n",
            "lockdown      this          stayhome      health        coronaviruspandemic\n",
            "stayathome    is            staysafe      care          covid„Éº19      \n",
            "extended      virus         stayathome    workers       covid2019     \n",
            "india         real          socialdistancinghealthcare    coronavirusoutbreak\n",
            "april         pass          stayhomesavelivespublic        covid19pandemic\n",
            "till          right         stayhealthy   patients      stayhomesavelives\n",
            "days          thing         flattenthecurvedoctors       corona        \n",
            "may           great         washyourhands hospital      coronavirususa\n",
            "due           week          savelives     nurses        what          \n",
            "weeks         really        love          medical       coronavirusupdate\n",
            "corona        shall         corona        support       life          \n",
            "covid2019     shit          covid„Éº19      staff         quarantineactivities\n",
            "extend        sad           easter        mental        coronavirusupdates\n",
            "2020          thread        staystrong    masks         meme          \n",
            "london        video         besafe        front         living        \n",
            "lockdown2020  read          covi          essential     coronalockdown\n",
            "police        needs         everyone      crisis        covidiots     \n",
            "21            to            d19           thanks        is            \n",
            "week          best          thelockdown   take          virus         \n",
            "end           joke          nigeria       minister      coronavirustruth\n",
            "\n",
            "\n",
            "topic 20      topic 21      topic 22      topic 23      topic 24      \n",
            "--------      --------      --------      --------      --------      \n",
            "day           world         get           time          social        \n",
            "today         china         like          first         distancing    \n",
            "every         virus         it            it            socialdistancing\n",
            "one           corona        one           take          media         \n",
            "another       who           going         difficult     distance      \n",
            "isolation     around        go            every         practice      \n",
            "single        whole         back          now           physical      \n",
            "14            countries     would         family        hands         \n",
            "first         country       if            long          spread        \n",
            "deaths        india         know          life          practicing    \n",
            "week          chinese       work          crisis        maintain      \n",
            "morning       war           good          spend         keep          \n",
            "april         usa           see           last          isolation     \n",
            "happy         coronavirusoutbreakthink         great         wash          \n",
            "last          wuhan         still         in            measures      \n",
            "night         save          really        living        rules         \n",
            "per           rest          so            spending      guidelines    \n",
            "beautiful     global        right         use           mask          \n",
            "since         let           make          for           face          \n",
            "good          fight         got           best          important     \n",
            "\n",
            "\n",
            "topic 25      topic 26      topic 27      topic 28      topic 29      \n",
            "--------      --------      --------      --------      --------      \n",
            "stayhomestaysafeplease        quarantine    you           pandemic      \n",
            "narendramodi  help          quarantinelifethank         global        \n",
            "easter        share         socialdistancingknow          response      \n",
            "happy         take          corona        to            fight         \n",
            "india         if            days          love          join          \n",
            "fight         stop          life          god           leaders       \n",
            "indiafightscoronasomeone       isolation     your          oneworld      \n",
            "pmoindia      need          quarantineandchillre            plan          \n",
            "hope          can           self          want          defeat        \n",
            "let           support       2020          much          how           \n",
            "pm            donate        my            heroes        let           \n",
            "good          follow        me            doctors       many          \n",
            "corona        retweet       california    great         due           \n",
            "together      read          tiktok        nurses        one           \n",
            "ji            family        14            working       stand         \n",
            "family        friends       bored         service       amid          \n",
            "light         dear          got           realdonaldtrumpin            \n",
            "stayhomeindia watch         covƒ±d19       everyone      support       \n",
            "friends       stayhomesaveliveswhen          front         during        \n",
            "stayhomesavelivesmake          music         essential     end           \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0eJDMhyriR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b2wJKd_riL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EGv6CGRriIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayOuYsGoriFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ0sXmWpriBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf27MdPtrh-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLAjYfqarh4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-xK9bknrh0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xIFk9-6rhxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}